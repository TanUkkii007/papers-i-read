{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from hyperparams import Hyperparams as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  tf.concat in embed\n",
    "\n",
    "n = 10\n",
    "lookup_table = tf.placeholder(tf.int32, name = 'lookup_table')\n",
    "pad = tf.zeros(shape=[1, n], dtype=tf.int32)\n",
    "g = tf.concat([pad, lookup_table[1:, :]], axis=0)\n",
    "\n",
    "lt = [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "         [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "         [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    a = sess.run(g, feed_dict={lookup_table: lt})\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function embedding_lookup in module tensorflow.python.ops.embedding_ops:\n",
      "\n",
      "embedding_lookup(params, ids, partition_strategy='mod', name=None, validate_indices=True, max_norm=None)\n",
      "    Looks up `ids` in a list of embedding tensors.\n",
      "    \n",
      "    This function is used to perform parallel lookups on the list of\n",
      "    tensors in `params`.  It is a generalization of\n",
      "    [`tf.gather()`](../../api_docs/python/array_ops.md#gather), where `params` is\n",
      "    interpreted as a partitioning of a large embedding tensor.  `params` may be\n",
      "    a `PartitionedVariable` as returned by using `tf.get_variable()` with a\n",
      "    partitioner.\n",
      "    \n",
      "    If `len(params) > 1`, each element `id` of `ids` is partitioned between\n",
      "    the elements of `params` according to the `partition_strategy`.\n",
      "    In all strategies, if the id space does not evenly divide the number of\n",
      "    partitions, each of the first `(max_id + 1) % len(params)` partitions will\n",
      "    be assigned one more id.\n",
      "    \n",
      "    If `partition_strategy` is `\"mod\"`, we assign each id to partition\n",
      "    `p = id % len(params)`. For instance,\n",
      "    13 ids are split across 5 partitions as:\n",
      "    `[[0, 5, 10], [1, 6, 11], [2, 7, 12], [3, 8], [4, 9]]`\n",
      "    \n",
      "    If `partition_strategy` is `\"div\"`, we assign ids to partitions in a\n",
      "    contiguous manner. In this case, 13 ids are split across 5 partitions as:\n",
      "    `[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10], [11, 12]]`\n",
      "    \n",
      "    The results of the lookup are concatenated into a dense\n",
      "    tensor. The returned tensor has shape `shape(ids) + shape(params)[1:]`.\n",
      "    \n",
      "    Args:\n",
      "      params: A single tensor representing the complete embedding tensor,\n",
      "        or a list of P tensors all of same shape except for the first dimension,\n",
      "        representing sharded embedding tensors.  Alternatively, a\n",
      "        `PartitionedVariable`, created by partitioning along dimension 0. Each\n",
      "        element must be appropriately sized for the given `partition_strategy`.\n",
      "      ids: A `Tensor` with type `int32` or `int64` containing the ids to be looked\n",
      "        up in `params`.\n",
      "      partition_strategy: A string specifying the partitioning strategy, relevant\n",
      "        if `len(params) > 1`. Currently `\"div\"` and `\"mod\"` are supported. Default\n",
      "        is `\"mod\"`.\n",
      "      name: A name for the operation (optional).\n",
      "      validate_indices: Whether or not to validate gather indices.\n",
      "      max_norm: If not None, embedding values are l2-normalized to the value of\n",
      "       max_norm.\n",
      "    \n",
      "    Returns:\n",
      "      A `Tensor` with the same type as the tensors in `params`.\n",
      "    \n",
      "    Raises:\n",
      "      ValueError: If `params` is empty.\n",
      "\n",
      "lookup_table = [[-0.45359232 -0.85074823  0.34374631]\n",
      " [-0.91181458  0.22338264 -1.71117524]\n",
      " [ 0.95973502 -0.59637926  0.63283693]\n",
      " [-0.93767676 -1.48733031 -0.73300532]\n",
      " [ 0.16576793 -0.09820374 -0.75246729]\n",
      " [ 0.78629857 -1.66523214  0.18375831]\n",
      " [ 1.49897316  0.69960007 -3.24587896]\n",
      " [-0.50191115 -0.79932961 -2.06624139]\n",
      " [ 0.72461598  0.96221569 -1.20209793]\n",
      " [ 0.19742772 -0.48094018 -0.10080108]]\n",
      "looked up embeddings = [[ 0.19742772 -0.48094018 -0.10080108]\n",
      " [ 0.72461598  0.96221569 -1.20209793]\n",
      " [-0.50191115 -0.79932961 -2.06624139]\n",
      " [ 1.49897316  0.69960007 -3.24587896]\n",
      " [ 0.78629857 -1.66523214  0.18375831]\n",
      " [ 0.16576793 -0.09820374 -0.75246729]\n",
      " [-0.93767676 -1.48733031 -0.73300532]\n",
      " [ 0.95973502 -0.59637926  0.63283693]\n",
      " [-0.91181458  0.22338264 -1.71117524]\n",
      " [-0.45359232 -0.85074823  0.34374631]]\n"
     ]
    }
   ],
   "source": [
    "# tf.nn.embedding_lookup in embed\n",
    "\n",
    "help(tf.nn.embedding_lookup)\n",
    "\n",
    "vocabulary_size = 10\n",
    "embedding_dimension = 3\n",
    "\n",
    "lookup_table = tf.constant(np.random.normal(size=[vocabulary_size, embedding_dimension]))\n",
    "inputs = tf.placeholder(tf.int32, name='inputs')\n",
    "\n",
    "g = tf.nn.embedding_lookup(lookup_table, inputs)\n",
    "\n",
    "input_value = [9,8,7,6,5,4,3,2,1,0]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "        lt = sess.run(lookup_table)\n",
    "        a = sess.run(g, feed_dict={inputs: input_value})\n",
    "print('lookup_table = {}'.format(lt))\n",
    "print('looked up embeddings = {}'.format(a))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
