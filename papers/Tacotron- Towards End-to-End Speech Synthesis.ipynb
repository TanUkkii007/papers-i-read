{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tacotron: Towards End-to-End Speech Synthesis\n",
    "\n",
    "Link: https://arxiv.org/abs/1703.10135\n",
    "\n",
    "Authors: Yuxuan Wang, RJ Skerry-Ryan, Daisy Stanton, Yonghui Wu, Ron J. Weiss, Navdeep Jaitly, Zongheng Yang, Ying Xiao, Zhifeng Chen, Samy Bengio, Quoc Le, Yannis Agiomyrgiannakis, Rob Clark, Rif A. Saurous\n",
    "\n",
    "Institution: Google, Inc.\n",
    "\n",
    "Publication: arXiv\n",
    "\n",
    "Date: 6 Apr 2017\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background Materials\n",
    "\n",
    "tacos & sushi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is this paper about?\n",
    "\n",
    "\n",
    "Tacotron, an end-to-end generative text-to-speech model that synthesizes speech directly from characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the motivation of this research?\n",
    "\n",
    "Traditional TTS pipelines are complex. For example, it includes a text frontend extracting various linguistic features, a duration model, an acoustic feature prediction, and signal-processing based vocoder. They require domain expertise and labor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What makes this paper different from previous research?\n",
    "\n",
    "\n",
    "Tacotron uses seq2seq with attention but does not require phoneme-level alignment, so there is no need to use pre-trained aligner.\n",
    "\n",
    "Tacotron directly predict raw spectrogram so does not use vocoder.\n",
    "\n",
    "Tacotron is complete end-to-end model, which can learn directly from `<text, audio>` pair to predict spectrogram, so can be trained completely from scratch.\n",
    "\n",
    "Tacotron predicts frame level spectrograms, so it is significantly faster than sample level models but relatively low quality in terms of naturalness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How this paper achieve it?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset used in this study\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementations\n",
    "\n",
    "- https://github.com/Kyubyong/tacotron\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Readings\n",
    "\n",
    "- Sequence to sequence learning with neural networks https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\n",
    "- Highway Networks https://arxiv.org/abs/1505.00387\n",
    "- Fully Character-Level Neural Machine Translation without Explicit Segmentation https://arxiv.org/abs/1610.03017"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
