{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Language Multi-Speaker Acoustic Modeling for LSTM-RNN based Statistical Parametric Speech Synthesis\n",
    "\n",
    "Link: https://research.google.com/pubs/pub45400.html\n",
    "\n",
    "Authors: Bo Li, Heiga Zen\n",
    "\n",
    "Institution: Google\n",
    "\n",
    "Publication: google research\n",
    "\n",
    "Date: 2016\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background Materials\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Papers citing this paper\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is this paper about?\n",
    "\n",
    "\n",
    "LSTM-RNN based statistic parametric speech synthesis system that uses data from multiple languages and speakers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the motivation of this research?\n",
    "\n",
    "\n",
    "The ability to utilize inhomogeneous data is important because it allows to use more large data for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What makes this paper different from previous research?\n",
    "\n",
    "- trained with inhomogeneous data\n",
    "- Adaption to a new language with limiting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How this paper achieve it?\n",
    "\n",
    "### Design\n",
    "For modeling language variation, cluster adaptive training (CAT) (Tan et al., 2015) is used.\n",
    "\n",
    "For modeling speaker variation, speaker dependent output layers are used.\n",
    "\n",
    "### Preprocessing\n",
    "A input sequence of words from language $u$ is first processed to extract a sequence of universal linguistic feature vectors. The union of the linguistic feature set of all the languages is used instead of the international phonetic alphabet (IPA) for simplicity. For feature dimensions that are not available in the current language zero padding is used.\n",
    "\n",
    "The universal linguistic feature vectors are converted to frame-level linguistic feature vectors $\\{x_1, ..., x_t, ..., x_T\\}$ by duration model.\n",
    "\n",
    "### Goal\n",
    "The goal of this system is\n",
    "\n",
    "to output a vocoder parameter feature vector $y_t^{(u, s)}$ for the desired language $u$ and speaker $s$,\n",
    "\n",
    "given for each frame at time $t$ the feature vector $x_t$ together with a language ID $u$ and a speaker ID $s$ as an input.\n",
    "\n",
    "\n",
    "### Components\n",
    "\n",
    "1. **mean tower $\\mathcal{M}^{\\mathrm{mean}}$**: a sub-network which captures the shared knowledge across different training languages.\n",
    "1. **language basis towers $\\mathcal{M}_l^{\\mathrm{lang}}$** for $l \\in \\{1,...,L\\}$: a set of sub-networks to capture different variation of all training languages. $L$ is the dimention of the language.\n",
    "1. **language code vector $\\lambda^{(u)}$** for each of the training languages $u \\in \\{1,...,U\\}$: Normally $L < U$ is met, i.e. the total number of languages $U$ is usually larger than the dimension of the language space $L$. This bottleneck structure forces the culustering of the given languages and enables information sharing between language.\n",
    "1. **speaker dependent RNN output layer $\\mathcal{M}_s^{\\mathrm{spkr}}$** onc for each speaker $s \\in \\{1,...,S\\}$\n",
    "\n",
    "#### speaker dependent RNN output layer\n",
    "\n",
    "The vocoder parameters can be derived as follows.\n",
    "\n",
    "$\\boldsymbol{h}_t^{(u)} = \\mathcal{M}^{\\mathrm{mean}}(\\{x_1, ..., x_t\\}) + \\sum_{l=1}^L\\lambda_l^{(u)}\\mathcal{M}_l^{\\mathrm{lang}}(\\{x_1, ..., x_t\\})$\n",
    "\n",
    "$\\boldsymbol{y}_t^{(u, s)} = \\mathcal{M}_s^{\\mathrm{spkr}}(\\boldsymbol{h}_t^{(u)}, \\boldsymbol{y}_{t-1}^{(u, s)})$\n",
    "\n",
    "The language mean tower $\\mathcal{M}^{\\mathrm{mean}}$ sets up the origin of the language space and each language basis tower $\\mathcal{M}_l^{\\mathrm{lang}}$ learns one potential direction of variation away from the origin.\n",
    "\n",
    "The language code vector $\\boldsymbol{\\lambda}^{(u)}$ locates the language $u$ in the $L$ dimensional space and converts the universal input linguistic feature vector $\\boldsymbol{x}_t$ to language dependent hidden activation $\\boldsymbol{h}_t^{(u)}$.\n",
    "\n",
    "$\\mathcal{M}^{\\mathrm{mean}}$, $\\mathcal{M}_l^{\\mathrm{lang}}$, $\\lambda^{(u)}$, $\\mathcal{M}_s^{\\mathrm{spkr}}$ will be updated during training for $(u, s)$ pair.\n",
    "\n",
    "<img src=\"img/Multi-Language_Multi-Speaker_Acoustic_Modeling_for_LSTM-RNN_based_Statistical_Parametric_Speech_Synthesis_Figure1.png\" width=\"400\">\n",
    "\n",
    "\n",
    "### Results\n",
    "\n",
    "#### AdaptationtoNewLanguages\n",
    "\n",
    "Six training language is selected and six basis towers and one mean tower were used to model the language space ($U = 6, L = 6$). \n",
    "\n",
    "Additional two language are selected for adaption with limiting training data ($U = 8, L = 6$).\n",
    "\n",
    "The experimented adaptation methods are following:\n",
    "\n",
    "- update only language code $\\lambda^{(u)}$;\n",
    "- v2 : update language code $\\lambda^{(u)}$ and mean tower $\\mathcal{M}^{\\mathrm{mean}}$ jointly;\n",
    "- v3 : start from v1, update mean tower $\\mathcal{M}^{\\mathrm{mean}}$ alone;\n",
    "- v4 : start from v3, joint update language $\\lambda^{(u)}$ and mean tower $\\mathcal{M}^{\\mathrm{mean}}$.\n",
    "\n",
    "Other than v1, the other methods yield lower mean square errors than directly building a system from the limited data.\n",
    "v2 and v3 are statistically better than baseline in preference tests.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset used in this study\n",
    "\n",
    "internal data\n",
    "\n",
    "### training language\n",
    "\n",
    "- North American (US) English\n",
    "- British (UK) English\n",
    "- French\n",
    "- Italian\n",
    "- German\n",
    "- Spanish\n",
    "\n",
    "### testing language for adaption\n",
    "\n",
    "- Polish\n",
    "- BR Portuguese"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementations\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Readings\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
