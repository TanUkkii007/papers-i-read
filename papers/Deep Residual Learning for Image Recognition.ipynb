{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Residual Learning for Image Recognition\n",
    "\n",
    "Link: https://arxiv.org/abs/1512.03385\n",
    "\n",
    "Authors: Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
    "\n",
    "Institution: Microsoft Research\n",
    "\n",
    "Publication: arXiv\n",
    "\n",
    "Date: 2015\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background Materials\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is this paper about?\n",
    "\n",
    "\n",
    "ResNet, \"very\" deep neural network architecture using residual learning, which is substantially deeper than those used previously for image recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the motivation of this research?\n",
    "\n",
    "Network depth is of crucial importance.\n",
    "\n",
    "However, deeper neural networks are more difficult to train.\n",
    "\n",
    "With the network depth increasing, accuracy gets aturated, and then degrades rapidly. This is called degradation problem.\n",
    "\n",
    "Let us consider shallower architecture and its deeper counterpart that add identity mapping layer onto it. The deeper model should produce no higher training error than its shallower counterpart. But experiments show that the deeper counterpart is unable to find solutions that are comparably better than shallower architecture.\n",
    "\n",
    "\n",
    "Figure1. Training error (left) and test error (right) on CIFAR-10.\n",
    "<img src=\"img/Deep_Residual_Learning_for_Image_Recognition_Figure1.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What makes this paper different from previous research?\n",
    "\n",
    "- using residual learning\n",
    "- very deep, up to 152 layers that is 8 times deeper than VGG\n",
    "- lower complexity even though the depth is significantly increased\n",
    "- low errors. ILSVRC 2015 winner.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How this paper achieve it?\n",
    "\n",
    "\n",
    "### Residual representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset used in this study\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementations\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Readings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
